{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import itertools\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import pickle\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are taking the output from 3_EDA to start doing the modeling. To recap on the missing steps, we will:\n",
    "\n",
    "#### `3. Model Selection`\n",
    "Given the nature the data, we might consider the following models:\n",
    "- **ARIMA/SARIMA**: If your data shows trends or autocorrelation. SARIMA is suitable if there is a clear seasonal pattern.\n",
    "- **Prophet**: Handles daily data well, robust to missing data, and good with seasonality.\n",
    "- **Machine Learning Approaches**: If there are other factors that can predict 'quantity', a model like Random Forest or Gradient Boosting might be useful.\n",
    "\n",
    "#### 4. Model Training and Forecasting\n",
    "- **Training**: Training the yearly data.\n",
    "- **Forecasting**: Generate predictions for the upcomming days.\n",
    "- **Hyperparameter Tuning**: Optimize model parameters for best performance.\n",
    "\n",
    "#### 5. Model Evaluation\n",
    "- **Performance Metrics**: Evaluate the model using appropriate metrics.\n",
    "- **Cross-Validation**: If possible, use time series cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a general approach to fitting an ARIMA model:\n",
    "\n",
    "Selecting Model Orders: You need to choose the SARIMA model orders. These include the non-seasonal parameters (p, d, q) and the seasonal. Since you've detrended the data, d might be 0 or 1 depending on if the data needs further differencing to achieve stationarity. The seasonal parameters will incorporate the seasonality you've observed.\n",
    "\n",
    "Seasonal Period (s): This is the seasonality of the data. In your case, if the seasonality is twice per month, you've already calculated the seasonal period to be approximately 365 hours.\n",
    "\n",
    "Parameter Estimation: Use the ACF and PACF plots of the detrended data to estimate the initial ARIMA parameters. You can also use grid search methods to test different combinations of parameters and select the best model based on some criteria like the AIC (Akaike Information Criterion).\n",
    "\n",
    "Model Diagnostics: After fitting the model, check the diagnostics to ensure that the residuals of your model are white noise (no autocorrelation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling by Country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do a separate model for each country taking the signla processed from the last EDA step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing date strings, ignoring any timezone information and converting them to datetime objects\n",
    "date_parser = lambda x: pd.to_datetime(x[:22])\n",
    "forecasted_values_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPAIN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset Spain\n",
    "model_spain_df = pd.read_csv(\"../3_EDA/EDA_countries/EDA_SP.csv\", \n",
    "                     converters={'EndTime': date_parser}).set_index('EndTime').dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "p = 1  # replace with actual\n",
    "d = 1  # replace with actual\n",
    "q = 1  # replace with actual\n",
    "\n",
    "# Fit the ARIMA model (using the known part of the time series)\n",
    "model = ARIMA(model_spain_df['detrended'], order=(p, d, q))\n",
    "model_fit = model.fit()\n",
    "\n",
    "# Forecast the missing values\n",
    "# The 'steps' argument would be the number of hours in the missing months\n",
    "forecast = model_fit.get_forecast(steps=1000) #hours in a monyh\n",
    "\n",
    "# The forecast object contains the predicted values and other information\n",
    "forecasted_values = forecast.predicted_mean\n",
    "\n",
    "# You may also want to extract the confidence intervals of the forecasts\n",
    "conf_int = forecast.conf_int()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tunning and Train / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ARIMA(2, 1, 2) AIC: 123821.37328905759\n",
      "Mean Squared Error: 264054434.661867\n",
      "Mean Absolute Error: 13138.66812549769\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Split the dataset into train and test sets (80-20 split)\n",
    "train_size = int(len(model_spain_df) * 0.8)\n",
    "train, test = model_spain_df.iloc[:train_size], model_spain_df.iloc[train_size:]\n",
    "\n",
    "# Define the p, d, and q ranges\n",
    "p = d = q = range(0, 3)  # Example ranges; adjust as needed\n",
    "\n",
    "# Generate all different combinations of p, d, and q triplets\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "\n",
    "# Initialize best score and parameters\n",
    "best_aic = float(\"inf\")\n",
    "best_order = None\n",
    "best_model = None\n",
    "\n",
    "# Grid search for the best ARIMA model on the training set\n",
    "for order in pdq:\n",
    "    try:\n",
    "        model = ARIMA(train['detrended'], order=order)\n",
    "        model_fit = model.fit()\n",
    "        if model_fit.aic < best_aic:\n",
    "            best_aic = model_fit.aic\n",
    "            best_order = order\n",
    "            best_model = model_fit\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(f'Best ARIMA{best_order} AIC: {best_aic}')\n",
    "\n",
    "# Forecasting on the test set\n",
    "forecast = best_model.get_forecast(steps=len(test))  # Forecasting as many steps as the test set\n",
    "forecasted_values = forecast.predicted_mean\n",
    "\n",
    "# Compute evaluation metrics\n",
    "mse = mean_squared_error(test['detrended'], forecasted_values)\n",
    "mae = mean_absolute_error(test['detrended'], forecasted_values)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Mean Absolute Error: {mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving Forecasted Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving value in dict\n",
    "forecasted_values_dict['Spain'] = forecasted_values.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving model in pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model to a file\n",
    "with open('../models/best_arima_model_SP.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POLAND Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ARIMA(2, 1, 2) AIC: 101967.019733206\n",
      "Mean Squared Error: 9385116.075622112\n",
      "Mean Absolute Error: 2629.4588517453353\n"
     ]
    }
   ],
   "source": [
    "# Reading the dataset Poland\n",
    "model_poland_df = pd.read_csv(\"../3_EDA/EDA_countries/EDA_PO.csv\", \n",
    "                     converters={'EndTime': date_parser}).set_index('EndTime').dropna()\n",
    "\n",
    "# Split the dataset into train and test sets (80-20 split)\n",
    "train_size = int(len(model_poland_df) * 0.8)\n",
    "train, test = model_poland_df.iloc[:train_size], model_poland_df.iloc[train_size:]\n",
    "\n",
    "# Define the p, d, and q ranges\n",
    "p = d = q = range(0, 3)  # Example ranges; adjust as needed\n",
    "\n",
    "# Generate all different combinations of p, d, and q triplets\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "\n",
    "# Initialize best score and parameters\n",
    "best_aic = float(\"inf\")\n",
    "best_order = None\n",
    "best_model = None\n",
    "\n",
    "# Grid search for the best ARIMA model on the training set\n",
    "for order in pdq:\n",
    "    try:\n",
    "        model = ARIMA(train['detrended'], order=order)\n",
    "        model_fit = model.fit()\n",
    "        if model_fit.aic < best_aic:\n",
    "            best_aic = model_fit.aic\n",
    "            best_order = order\n",
    "            best_model = model_fit\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(f'Best ARIMA{best_order} AIC: {best_aic}')\n",
    "\n",
    "# Forecasting on the test set\n",
    "forecast = best_model.get_forecast(steps=len(test))  # Forecasting as many steps as the test set\n",
    "forecasted_values = forecast.predicted_mean\n",
    "\n",
    "# Compute evaluation metrics\n",
    "mse = mean_squared_error(test['detrended'], forecasted_values)\n",
    "mae = mean_absolute_error(test['detrended'], forecasted_values)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "\n",
    "# Saving value in dict\n",
    "forecasted_values_dict['Poland'] = forecasted_values.iloc[0]\n",
    "\n",
    "# Save the best model to a file\n",
    "with open('../models/best_arima_model_PO.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DENMARK Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ARIMA(2, 0, 2) AIC: 92253.64272046028\n",
      "Mean Squared Error: 1709821.646026413\n",
      "Mean Absolute Error: 1071.8352269360382\n"
     ]
    }
   ],
   "source": [
    "# Reading the dataset Denmark\n",
    "model_denmark_df = pd.read_csv(\"../3_EDA/EDA_countries/EDA_DK.csv\", \n",
    "                     converters={'EndTime': date_parser}).set_index('EndTime').dropna()\n",
    "\n",
    "# Split the dataset into train and test sets (80-20 split)\n",
    "train_size = int(len(model_denmark_df) * 0.8)\n",
    "train, test = model_denmark_df.iloc[:train_size], model_denmark_df.iloc[train_size:]\n",
    "\n",
    "# Define the p, d, and q ranges\n",
    "p = d = q = range(0, 3)  # Example ranges; adjust as needed\n",
    "\n",
    "# Generate all different combinations of p, d, and q triplets\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "\n",
    "# Initialize best score and parameters\n",
    "best_aic = float(\"inf\")\n",
    "best_order = None\n",
    "best_model = None\n",
    "\n",
    "# Grid search for the best ARIMA model on the training set\n",
    "for order in pdq:\n",
    "    try:\n",
    "        model = ARIMA(train['detrended'], order=order)\n",
    "        model_fit = model.fit()\n",
    "        if model_fit.aic < best_aic:\n",
    "            best_aic = model_fit.aic\n",
    "            best_order = order\n",
    "            best_model = model_fit\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(f'Best ARIMA{best_order} AIC: {best_aic}')\n",
    "\n",
    "# Forecasting on the test set\n",
    "forecast = best_model.get_forecast(steps=len(test))  # Forecasting as many steps as the test set\n",
    "forecasted_values = forecast.predicted_mean\n",
    "\n",
    "# Compute evaluation metrics\n",
    "mse = mean_squared_error(test['detrended'], forecasted_values)\n",
    "mae = mean_absolute_error(test['detrended'], forecasted_values)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "\n",
    "# Saving value in dict\n",
    "forecasted_values_dict['Poland'] = forecasted_values.iloc[0]\n",
    "\n",
    "# Save the best model to a file\n",
    "with open('../models/best_arima_model_DK.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SWEEDEN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ARIMA(2, 0, 2) AIC: 97241.05130632836\n",
      "Mean Squared Error: 1784595.9373301351\n",
      "Mean Absolute Error: 1025.10073167753\n"
     ]
    }
   ],
   "source": [
    "# Reading the dataset Sweeden\n",
    "model_sweeden_df = pd.read_csv(\"../3_EDA/EDA_countries/EDA_SE.csv\", \n",
    "                     converters={'EndTime': date_parser}).set_index('EndTime').dropna()\n",
    "\n",
    "# Split the dataset into train and test sets (80-20 split)\n",
    "train_size = int(len(model_sweeden_df) * 0.8)\n",
    "train, test = model_sweeden_df.iloc[:train_size], model_sweeden_df.iloc[train_size:]\n",
    "\n",
    "# Define the p, d, and q ranges\n",
    "p = d = q = range(0, 3)  # Example ranges; adjust as needed\n",
    "\n",
    "# Generate all different combinations of p, d, and q triplets\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "\n",
    "# Initialize best score and parameters\n",
    "best_aic = float(\"inf\")\n",
    "best_order = None\n",
    "best_model = None\n",
    "\n",
    "# Grid search for the best ARIMA model on the training set\n",
    "for order in pdq:\n",
    "    try:\n",
    "        model = ARIMA(train['detrended'], order=order)\n",
    "        model_fit = model.fit()\n",
    "        if model_fit.aic < best_aic:\n",
    "            best_aic = model_fit.aic\n",
    "            best_order = order\n",
    "            best_model = model_fit\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(f'Best ARIMA{best_order} AIC: {best_aic}')\n",
    "\n",
    "# Forecasting on the test set\n",
    "forecast = best_model.get_forecast(steps=len(test))  # Forecasting as many steps as the test set\n",
    "forecasted_values = forecast.predicted_mean\n",
    "\n",
    "# Compute evaluation metrics\n",
    "mse = mean_squared_error(test['detrended'], forecasted_values)\n",
    "mae = mean_absolute_error(test['detrended'], forecasted_values)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "\n",
    "# Saving value in dict\n",
    "forecasted_values_dict['Sweeden'] = forecasted_values.iloc[0]\n",
    "\n",
    "# Save the best model to a file\n",
    "with open('../models/best_arima_model_SE.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NETHERLANDS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ARIMA(2, 1, 2) AIC: 115764.7337641639\n",
      "Mean Squared Error: 72803800.19662891\n",
      "Mean Absolute Error: 6896.542038156176\n"
     ]
    }
   ],
   "source": [
    "# Reading the dataset Netherlands\n",
    "model_ned_df = pd.read_csv(\"../3_EDA/EDA_countries/EDA_NE.csv\", \n",
    "                     converters={'EndTime': date_parser}).set_index('EndTime').dropna()\n",
    "\n",
    "# Split the dataset into train and test sets (80-20 split)\n",
    "train_size = int(len(model_ned_df) * 0.8)\n",
    "train, test = model_ned_df.iloc[:train_size], model_ned_df.iloc[train_size:]\n",
    "\n",
    "# Define the p, d, and q ranges\n",
    "p = d = q = range(0, 3)  # Example ranges; adjust as needed\n",
    "\n",
    "# Generate all different combinations of p, d, and q triplets\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "\n",
    "# Initialize best score and parameters\n",
    "best_aic = float(\"inf\")\n",
    "best_order = None\n",
    "best_model = None\n",
    "\n",
    "# Grid search for the best ARIMA model on the training set\n",
    "for order in pdq:\n",
    "    try:\n",
    "        model = ARIMA(train['detrended'], order=order)\n",
    "        model_fit = model.fit()\n",
    "        if model_fit.aic < best_aic:\n",
    "            best_aic = model_fit.aic\n",
    "            best_order = order\n",
    "            best_model = model_fit\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(f'Best ARIMA{best_order} AIC: {best_aic}')\n",
    "\n",
    "# Forecasting on the test set\n",
    "forecast = best_model.get_forecast(steps=len(test))  # Forecasting as many steps as the test set\n",
    "forecasted_values = forecast.predicted_mean\n",
    "\n",
    "# Compute evaluation metrics\n",
    "mse = mean_squared_error(test['detrended'], forecasted_values)\n",
    "mae = mean_absolute_error(test['detrended'], forecasted_values)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "\n",
    "# Saving value in dict\n",
    "forecasted_values_dict['Netherlands'] = forecasted_values.iloc[0]\n",
    "\n",
    "# Save the best model to a file\n",
    "with open('../models/best_arima_model_NE.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GERMANY Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ARIMA(2, 1, 2) AIC: 135040.59889130667\n",
      "Mean Squared Error: 1310454216.1989555\n",
      "Mean Absolute Error: 29935.81739021916\n"
     ]
    }
   ],
   "source": [
    "# Reading the dataset Denmark\n",
    "model_ger_df = pd.read_csv(\"../3_EDA/EDA_countries/EDA_DE.csv\", \n",
    "                     converters={'EndTime': date_parser}).set_index('EndTime').dropna()\n",
    "\n",
    "# Split the dataset into train and test sets (80-20 split)\n",
    "train_size = int(len(model_ger_df) * 0.8)\n",
    "train, test = model_ger_df.iloc[:train_size], model_ger_df.iloc[train_size:]\n",
    "\n",
    "# Define the p, d, and q ranges\n",
    "p = d = q = range(0, 3)  # Example ranges; adjust as needed\n",
    "\n",
    "# Generate all different combinations of p, d, and q triplets\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "\n",
    "# Initialize best score and parameters\n",
    "best_aic = float(\"inf\")\n",
    "best_order = None\n",
    "best_model = None\n",
    "\n",
    "# Grid search for the best ARIMA model on the training set\n",
    "for order in pdq:\n",
    "    try:\n",
    "        model = ARIMA(train['detrended'], order=order)\n",
    "        model_fit = model.fit()\n",
    "        if model_fit.aic < best_aic:\n",
    "            best_aic = model_fit.aic\n",
    "            best_order = order\n",
    "            best_model = model_fit\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(f'Best ARIMA{best_order} AIC: {best_aic}')\n",
    "\n",
    "# Forecasting on the test set\n",
    "forecast = best_model.get_forecast(steps=len(test))  # Forecasting as many steps as the test set\n",
    "forecasted_values = forecast.predicted_mean\n",
    "\n",
    "# Compute evaluation metrics\n",
    "mse = mean_squared_error(test['detrended'], forecasted_values)\n",
    "mae = mean_absolute_error(test['detrended'], forecasted_values)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "\n",
    "# Saving value in dict\n",
    "forecasted_values_dict['Germany'] = forecasted_values.iloc[0]\n",
    "\n",
    "# Save the best model to a file\n",
    "with open('../models/best_arima_model_DE.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UK Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ARIMA(2, 1, 2) AIC: 13860.657872593514\n",
      "Mean Squared Error: 277639.4118961378\n",
      "Mean Absolute Error: 421.40105735093755\n"
     ]
    }
   ],
   "source": [
    "# Reading the dataset UK\n",
    "model_uk_df = pd.read_csv(\"../3_EDA/EDA_countries/EDA_UK.csv\", \n",
    "                     converters={'EndTime': date_parser}).set_index('EndTime').dropna()\n",
    "\n",
    "# Split the dataset into train and test sets (80-20 split)\n",
    "train_size = int(len(model_uk_df) * 0.8)\n",
    "train, test = model_uk_df.iloc[:train_size], model_uk_df.iloc[train_size:]\n",
    "\n",
    "# Define the p, d, and q ranges\n",
    "p = d = q = range(0, 3)  # Example ranges; adjust as needed\n",
    "\n",
    "# Generate all different combinations of p, d, and q triplets\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "\n",
    "# Initialize best score and parameters\n",
    "best_aic = float(\"inf\")\n",
    "best_order = None\n",
    "best_model = None\n",
    "\n",
    "# Grid search for the best ARIMA model on the training set\n",
    "for order in pdq:\n",
    "    try:\n",
    "        model = ARIMA(train['detrended'], order=order)\n",
    "        model_fit = model.fit()\n",
    "        if model_fit.aic < best_aic:\n",
    "            best_aic = model_fit.aic\n",
    "            best_order = order\n",
    "            best_model = model_fit\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(f'Best ARIMA{best_order} AIC: {best_aic}')\n",
    "\n",
    "# Forecasting on the test set\n",
    "forecast = best_model.get_forecast(steps=len(test))  # Forecasting as many steps as the test set\n",
    "forecasted_values = forecast.predicted_mean\n",
    "\n",
    "# Compute evaluation metrics\n",
    "mse = mean_squared_error(test['detrended'], forecasted_values)\n",
    "mae = mean_absolute_error(test['detrended'], forecasted_values)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "\n",
    "# Saving value in dict\n",
    "forecasted_values_dict['UK'] = forecasted_values.iloc[0]\n",
    "\n",
    "# Save the best model to a file\n",
    "with open('../models/best_arima_model_UK.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ITALY Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ARIMA(2, 1, 1) AIC: 62189.27592911603\n",
      "Mean Squared Error: 44210889.877709255\n",
      "Mean Absolute Error: 5422.750973369246\n"
     ]
    }
   ],
   "source": [
    "# Reading the dataset Italy\n",
    "model_it_df = pd.read_csv(\"../3_EDA/EDA_countries/EDA_IT.csv\", \n",
    "                     converters={'EndTime': date_parser}).set_index('EndTime').dropna()\n",
    "\n",
    "# Split the dataset into train and test sets (80-20 split)\n",
    "train_size = int(len(model_it_df) * 0.8)\n",
    "train, test = model_it_df.iloc[:train_size], model_it_df.iloc[train_size:]\n",
    "\n",
    "# Define the p, d, and q ranges\n",
    "p = d = q = range(0, 3)  # Example ranges; adjust as needed\n",
    "\n",
    "# Generate all different combinations of p, d, and q triplets\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "\n",
    "# Initialize best score and parameters\n",
    "best_aic = float(\"inf\")\n",
    "best_order = None\n",
    "best_model = None\n",
    "\n",
    "# Grid search for the best ARIMA model on the training set\n",
    "for order in pdq:\n",
    "    try:\n",
    "        model = ARIMA(train['detrended'], order=order)\n",
    "        model_fit = model.fit()\n",
    "        if model_fit.aic < best_aic:\n",
    "            best_aic = model_fit.aic\n",
    "            best_order = order\n",
    "            best_model = model_fit\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(f'Best ARIMA{best_order} AIC: {best_aic}')\n",
    "\n",
    "# Forecasting on the test set\n",
    "forecast = best_model.get_forecast(steps=len(test))  # Forecasting as many steps as the test set\n",
    "forecasted_values = forecast.predicted_mean\n",
    "\n",
    "# Compute evaluation metrics\n",
    "mse = mean_squared_error(test['detrended'], forecasted_values)\n",
    "mae = mean_absolute_error(test['detrended'], forecasted_values)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "\n",
    "# Saving value in dict\n",
    "forecasted_values_dict['Italy'] = forecasted_values.iloc[0]\n",
    "\n",
    "# Save the best model to a file\n",
    "with open('../models/best_arima_model_IT.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HUNGARY Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ARIMA(2, 1, 2) AIC: 103541.18900170678\n",
      "Mean Squared Error: 7815637.281220619\n",
      "Mean Absolute Error: 2372.265075446539\n"
     ]
    }
   ],
   "source": [
    "# Reading the dataset Hungary\n",
    "model_hun_df = pd.read_csv(\"../3_EDA/EDA_countries/EDA_HU.csv\", \n",
    "                     converters={'EndTime': date_parser}).set_index('EndTime').dropna()\n",
    "\n",
    "# Split the dataset into train and test sets (80-20 split)\n",
    "train_size = int(len(model_hun_df) * 0.8)\n",
    "train, test = model_hun_df.iloc[:train_size], model_hun_df.iloc[train_size:]\n",
    "\n",
    "# Define the p, d, and q ranges\n",
    "p = d = q = range(0, 3)  # Example ranges; adjust as needed\n",
    "\n",
    "# Generate all different combinations of p, d, and q triplets\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "\n",
    "# Initialize best score and parameters\n",
    "best_aic = float(\"inf\")\n",
    "best_order = None\n",
    "best_model = None\n",
    "\n",
    "# Grid search for the best ARIMA model on the training set\n",
    "for order in pdq:\n",
    "    try:\n",
    "        model = ARIMA(train['detrended'], order=order)\n",
    "        model_fit = model.fit()\n",
    "        if model_fit.aic < best_aic:\n",
    "            best_aic = model_fit.aic\n",
    "            best_order = order\n",
    "            best_model = model_fit\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(f'Best ARIMA{best_order} AIC: {best_aic}')\n",
    "\n",
    "# Forecasting on the test set\n",
    "forecast = best_model.get_forecast(steps=len(test))  # Forecasting as many steps as the test set\n",
    "forecasted_values = forecast.predicted_mean\n",
    "\n",
    "# Compute evaluation metrics\n",
    "mse = mean_squared_error(test['detrended'], forecasted_values)\n",
    "mae = mean_absolute_error(test['detrended'], forecasted_values)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "\n",
    "# Saving value in dict\n",
    "forecasted_values_dict['Hungary'] = forecasted_values.iloc[0]\n",
    "\n",
    "# Save the best model to a file\n",
    "with open('../models/best_arima_model_HU.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasted Country with Greater Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Spain': 21042.00489669611,\n",
       " 'Poland': -1039.8978309942197,\n",
       " 'Sweeden': -97.33877070294022,\n",
       " 'Netherlands': 1281.8994967560648,\n",
       " 'Germany': 19194.084806305484,\n",
       " 'UK': 781.5245527120798,\n",
       " 'Italy': 5424.729903671684,\n",
       " 'Hungary': 630.0741785469036}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecasted_values_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The country with the greatest forecasted value is: Spain\n"
     ]
    }
   ],
   "source": [
    "# Find the country with the highest forecasted value\n",
    "country_with_max_value = max(forecasted_values_dict, key=forecasted_values_dict.get)\n",
    "\n",
    "print(f\"The country with the greatest forecasted value is: {country_with_max_value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
